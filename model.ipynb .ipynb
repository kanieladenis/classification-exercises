{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021f5267",
   "metadata": {},
   "source": [
    "# Decision Tree Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3136fc3",
   "metadata": {},
   "source": [
    "#### Using Titanic Data\n",
    "- Remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caaae70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc24f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire Data\n",
    "df = acquire.get_titanic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.clean_titanic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2898b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ea807",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 1a) What is your baseline prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e622ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns='survived')\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns='survived')\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns='survived')\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a53615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most often used case in survived\n",
    "y_train.value_counts() #most frequent is not_survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb98ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mode is a great baseline\n",
    "baseline = y_train.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = (y_train == 0)\n",
    "matches_baseline_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458dbbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Baseline Prediction to 0 or Not_Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5c953",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 1a) What is your baseline accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b311a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")### ??? Removed column for baseline because it threw off the validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035a165",
   "metadata": {},
   "source": [
    "### Baseline accuracy is 61.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb885e",
   "metadata": {},
   "source": [
    "## <font color = 'red'>2) Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082e8e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501dc36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62adcc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3814e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8df4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(clf, feature_names= X_train.columns, rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c6b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction on train obeservations\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb541a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide probabiblity on train observations\n",
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c382cb",
   "metadata": {},
   "source": [
    "## <font color = 'red' >3) Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bf7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computer Accuracy Score\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba2241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Confusion Matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff90b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3b9402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Classification Report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942bf140",
   "metadata": {},
   "source": [
    "## <font color = 'red'>4) Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c618c9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find true positive rate, false positive rate, true negative rate, false negative rate\n",
    "# Compute TPR,TNR,FPR,FNR\n",
    "TP = 294\n",
    "TN = 114\n",
    "FP = 77\n",
    "FN = 13\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "accuracy = (TP + TN) / ALL\n",
    "TPR = TP / (TP + FN) \n",
    "TNR = TN / (TN + FP) \n",
    "FNR = FN / (FN + TP)  \n",
    "FPR = FP / (FP + TN) \n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1_score = 2* (precision*recall) / (precision+recall)\n",
    "support_pos = TP + FN\n",
    "support_neg = TN + FP\n",
    "\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'True Positive Rate: {TPR}')\n",
    "print(f'True Negative Rate: {TNR}')\n",
    "print(f'False Positive Rate: {FPR}')\n",
    "print(f'False Negative Rate: {FNR}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "print(f'support_pos: {support_pos}')\n",
    "print(f'support_neg: {support_neg}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ebd73c",
   "metadata": {},
   "source": [
    "## <font color = 'red'>5) Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dd8a62",
   "metadata": {},
   "source": [
    "### <font color = 'red'> Using Max_Depth 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cf3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object increasing max_depth to 4\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=123)\n",
    "# Fit the Model\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f317e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction on train obeservations\n",
    "y_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae7175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find probability of train observations\n",
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33058fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Accuracy\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1520596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Confusion Matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8217bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838be5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b58ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create classification report to find precision, reall, f1-score, support\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20507a0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find true positive rate, false positive rate, true negative rate, false negative rate\n",
    "# Compute TPR,TNR,FPR,FNR\n",
    "TP = 298\n",
    "TN = 116\n",
    "FP = 75\n",
    "FN = 9\n",
    "\n",
    "TPR = TP / (TP + FN) \n",
    "TNR = TN / (TN + FP) \n",
    "FNR = FN / (FN + TP)  \n",
    "FPR = FP / (FP + TN) \n",
    "\n",
    "\n",
    "print(f'True Positive Rate: {TPR}')\n",
    "print(f'True Negative Rate: {TNR}')\n",
    "print(f'False Positive Rate: {FPR}')\n",
    "print(f'False Negative Rate: {FNR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830f5fa8",
   "metadata": {},
   "source": [
    "### <font color = 'red'> Using Max_Depth 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f636048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object increasing max_depth to 5\n",
    "clf = DecisionTreeClassifier(max_depth=5, random_state=123)\n",
    "# Fit the Model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "# make prediction on train obeservations\n",
    "y_pred = clf.predict(X_train)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bf6055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Accuracy\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fabad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424dd34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find true positive rate, false positive rate, true negative rate, false negative rate\n",
    "# Compute TPR,TNR,FPR,FNR\n",
    "TP = 291\n",
    "TN = 131\n",
    "FP = 60\n",
    "FN = 16\n",
    "\n",
    "TPR = TP / (TP + FN) \n",
    "TNR = TN / (TN + FP) \n",
    "FNR = FN / (FN + TP)  \n",
    "FPR = FP / (FP + TN) \n",
    "\n",
    "\n",
    "print(f'True Positive Rate: {TPR}')\n",
    "print(f'True Negative Rate: {TNR}')\n",
    "print(f'False Positive Rate: {FPR}')\n",
    "print(f'False Negative Rate: {FNR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3635aa",
   "metadata": {},
   "source": [
    "### <font color = 'red'> Using Max_Depth 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b394707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object increasing max_depth to 6\n",
    "clf = DecisionTreeClassifier(max_depth=6, random_state=123)\n",
    "# Fit the Model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "# make prediction on train obeservations\n",
    "y_pred = clf.predict(X_train)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061481ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Accuracy\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc10d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc77542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find true positive rate, false positive rate, true negative rate, false negative rate\n",
    "# Compute TPR,TNR,FPR,FNR\n",
    "TP = 282\n",
    "TN = 151\n",
    "FP = 40\n",
    "FN = 25\n",
    "\n",
    "TPR = TP / (TP + FN) \n",
    "TNR = TN / (TN + FP) \n",
    "FNR = FN / (FN + TP)  \n",
    "FPR = FP / (FP + TN) \n",
    "\n",
    "\n",
    "print(f'True Positive Rate: {TPR}')\n",
    "print(f'True Negative Rate: {TNR}')\n",
    "print(f'False Positive Rate: {FPR}')\n",
    "print(f'False Negative Rate: {FNR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9903ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,20):\n",
    "    # Create the Decision Tree Object increasing max_depth to 6\n",
    "    clf = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "    \n",
    "    # Fit the Model\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction on train obeservations\n",
    "    y_pred = clf.predict(X_train)\n",
    "    \n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_pred, output_dict=True)\n",
    "    print(f\"Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66051666",
   "metadata": {},
   "source": [
    "## <font color='red'>6) Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe16be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model using Max Depth 6 because it has the best accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b75cdca",
   "metadata": {},
   "source": [
    "## <font color = 'red'>7) Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9295e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object increasing max_depth to 3\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "# Fit the Model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "# make prediction on train obeservations\n",
    "y_pred = clf.predict(X_validate)\n",
    "\n",
    "print(clf.score(X_validate, y_validate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db06571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b731d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8511f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object increasing max_depth to 4\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=123)\n",
    "# Fit the Model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_validate, y_validate))\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc04d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object increasing max_depth to 5\n",
    "clf = DecisionTreeClassifier(max_depth=5, random_state=123)\n",
    "# Fit the Model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_validate, y_validate))\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af883ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object increasing max_depth to 6\n",
    "clf = DecisionTreeClassifier(max_depth=6, random_state=123)\n",
    "# Fit the Model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_validate, y_validate))\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d544aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(2, 25):\n",
    "    # Make the model\n",
    "    clf = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = clf.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = clf.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca32f1",
   "metadata": {},
   "source": [
    "### Model with Max_Depth 6 has the best F1-Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bfb3d4",
   "metadata": {},
   "source": [
    "# <font color='red'> Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586a5053",
   "metadata": {},
   "source": [
    "##  <font color='red'> 1) Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a219d154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Model's Object\n",
    "rf = RandomForestClassifier(max_depth=10,\n",
    "                           random_state=123,\n",
    "                           min_samples_leaf=1)\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5957a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the Data to the model\n",
    "rf = rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a386683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Feature (column) Importances. sex_male (48%) has the most importance\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "y_pred = rf.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b80aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Probabability of each Prediction\n",
    "y_pred_proba = rf.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1336d368",
   "metadata": {},
   "source": [
    "##  <font color='red'> 2) Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd68dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Model Score for Accuracy\n",
    "rf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f3d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Confusion Matrix\n",
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48feca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70606050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_pred, output_dict=True)\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43fb93a",
   "metadata": {},
   "source": [
    "##  <font color='red'> 3) Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 293\n",
    "FP = 56\n",
    "FN = 14\n",
    "TN = 135\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1367c27d",
   "metadata": {},
   "source": [
    "##  <font color='red'> 4) Run through steps increasing your min_samples_leaf and decreasing your max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8157fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    rf = RandomForestClassifier(max_depth=11-i,\n",
    "                           random_state=123,\n",
    "                           min_samples_leaf=i)\n",
    "    rf = rf.fit(X_train,y_train)\n",
    "    y_pred = rf.predict(X_train)\n",
    "    report = classification_report(y_train, y_pred, output_dict=True)\n",
    "    print(f\"Random Forest with max_depth of {11-i} and min_sample_leaf {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b72f46",
   "metadata": {},
   "source": [
    "##  <font color='red'> 5a) What are the differences in the evaluation metrics? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c012ab",
   "metadata": {},
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24532ee",
   "metadata": {},
   "source": [
    "##  <font color='red'> 5a)Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae93bbda",
   "metadata": {},
   "source": [
    "Random Forest with max_depth of 8 and min_sample_leaf 3 performs best. ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dd2c14",
   "metadata": {},
   "source": [
    "##  <font color='red'> 6) After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070931b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    # Make the model\n",
    "    rf = RandomForestClassifier(max_depth=11-i,\n",
    "                           random_state=123,\n",
    "                           min_samples_leaf=i)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = rf.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = rf.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": 11-i,\n",
    "        \"min_sample\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b70ebe",
   "metadata": {},
   "source": [
    "### model with max_depth = 2, min_sample = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d49069",
   "metadata": {},
   "source": [
    "# <font color = 'red'> K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db0bddb",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 1) Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7e83b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model object\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit data to model object\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3618d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prediction array based on train data set using model\n",
    "y_pred = knn.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5867763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See class of data. 0=Did Not Surviv, 1 = Survived\n",
    "knn.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Probablity of Prediction (Did Not Survive) being correction\n",
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da1e722",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 2) Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy Score for KNN. 83% accurate\n",
    "knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bbe17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Confusion Matrix\n",
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f7a3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815a565d",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 3) Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e3d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 273\n",
    "TN = 139\n",
    "FP = 52\n",
    "FN = 34\n",
    "\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de83828",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 4) Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb32f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model object based on k = 10\n",
    "knn = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "# fit data to model object\n",
    "knn.fit(X_train, y_train)\n",
    "# Create Prediction Array\n",
    "y_pred = knn.predict(X_train)\n",
    "\n",
    "print(knn.score(X_train, y_train))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3464faf9",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 5) Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59772000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model object based on k = 20\n",
    "knn = KNeighborsClassifier(n_neighbors=20, weights='uniform')\n",
    "# fit data to model object\n",
    "knn.fit(X_train, y_train)\n",
    "# Create Prediction Array\n",
    "y_pred = knn.predict(X_train)\n",
    "\n",
    "print(knn.score(X_train, y_train))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f14a8",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 6) What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9028a",
   "metadata": {},
   "source": [
    "### Model with K=10 provides 81% Accuracy vs Model with K=20 provides 82% Accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a243cc0",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 7) Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3707f5b",
   "metadata": {},
   "source": [
    "### Model with K=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62273c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model object based on k = 10\n",
    "knn = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "# fit data to model object\n",
    "knn.fit(X_train, y_train)\n",
    "# Create Prediction Array\n",
    "y_pred = knn.predict(X_train)\n",
    "\n",
    "print(knn.score(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bbc1a6",
   "metadata": {},
   "source": [
    "### Model with K=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc71eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model object based on k = 20\n",
    "knn = KNeighborsClassifier(n_neighbors=20, weights='uniform')\n",
    "# fit data to model object\n",
    "knn.fit(X_train, y_train)\n",
    "# Create Prediction Array\n",
    "y_pred = knn.predict(X_train)\n",
    "\n",
    "print(knn.score(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48c6ac9",
   "metadata": {},
   "source": [
    "### Model with K=10 has better accuracy because K=20 includes too much noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d4382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(1,21):\n",
    "    # Make the model\n",
    "    knn = KNeighborsClassifier(n_neighbors=i, weights='uniform')\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    knn = knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = knn.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = knn.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"K_Neighbor\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c17b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.difference.abs().idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7480f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1, 21)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,5,10,15,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b1666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id columns\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee340c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce features\n",
    "x_cols = ['pclass','alone', 'sex_male']\n",
    "y_col = 'survived'\n",
    "\n",
    "X_train, y_train = train[x_cols], train[y_col]\n",
    "X_validate, y_validate = validate[x_cols], validate[y_col]\n",
    "X_test, y_test = test[x_cols], test[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca134cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(1,21):\n",
    "    # Make the model\n",
    "    knn = KNeighborsClassifier(n_neighbors=i, weights='uniform')\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    knn = knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = knn.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = knn.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"K_Neighbor\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.difference.abs().idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c6de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "# loop through different values of k\n",
    "for k in range(1, 21):\n",
    "            \n",
    "    # define the thing\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # fit the thing (remmeber only fit on training data)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # use the thing (calculate accuracy)\n",
    "    train_accuracy = knn.score(X_train, y_train)\n",
    "    validate_accuracy = knn.score(X_validate, y_validate)\n",
    "    \n",
    "    output = {\n",
    "        \"k\": k,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"validate_accuracy\": validate_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "\n",
    "# make a dataframe\n",
    "results = pd.DataFrame(metrics)\n",
    "\n",
    "# plot the data\n",
    "results.set_index('k').plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e1c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce features\n",
    "x_cols = ['pclass','alone', 'sex_male']\n",
    "y_col = 'survived'\n",
    "\n",
    "X_train, y_train = train[x_cols], train[y_col]\n",
    "X_validate, y_validate = validate[x_cols], validate[y_col]\n",
    "X_test, y_test = test[x_cols], test[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2533882",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "# loop through different values of k\n",
    "for k in range(1, 21):\n",
    "            \n",
    "    # define the thing\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # fit the thing (remmeber only fit on training data)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # use the thing (calculate accuracy)\n",
    "    train_accuracy = knn.score(X_train, y_train)\n",
    "    validate_accuracy = knn.score(X_validate, y_validate)\n",
    "    \n",
    "    output = {\n",
    "        \"k\": k,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"validate_accuracy\": validate_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "\n",
    "# make a dataframe\n",
    "results = pd.DataFrame(metrics)\n",
    "\n",
    "# plot the data\n",
    "results.set_index('k').plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e558966d",
   "metadata": {},
   "source": [
    "# <font color='red'> Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec305185",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 1) Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fda602d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = acquire.get_titanic()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2109737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 12), (214, 12), (179, 12))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validate, test = prepare.prep_titanic(df)\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0337fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179 entries, 561 to 53\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   survived                 179 non-null    int64  \n",
      " 1   pclass                   179 non-null    int64  \n",
      " 2   sex                      179 non-null    object \n",
      " 3   age                      179 non-null    float64\n",
      " 4   sibsp                    179 non-null    int64  \n",
      " 5   parch                    179 non-null    int64  \n",
      " 6   fare                     179 non-null    float64\n",
      " 7   embark_town              179 non-null    object \n",
      " 8   alone                    179 non-null    int64  \n",
      " 9   sex_male                 179 non-null    uint8  \n",
      " 10  embark_town_Queenstown   179 non-null    uint8  \n",
      " 11  embark_town_Southampton  179 non-null    uint8  \n",
      "dtypes: float64(2), int64(5), object(2), uint8(3)\n",
      "memory usage: 14.5+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5558c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['sex','embark_town'])\n",
    "validate = validate.drop(columns=['sex','embark_town'])\n",
    "test = test.drop(columns=['sex','embark_town'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c84cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 498 entries, 583 to 744\n",
      "Data columns (total 10 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   survived                 498 non-null    int64  \n",
      " 1   pclass                   498 non-null    int64  \n",
      " 2   age                      498 non-null    float64\n",
      " 3   sibsp                    498 non-null    int64  \n",
      " 4   parch                    498 non-null    int64  \n",
      " 5   fare                     498 non-null    float64\n",
      " 6   alone                    498 non-null    int64  \n",
      " 7   sex_male                 498 non-null    uint8  \n",
      " 8   embark_town_Queenstown   498 non-null    uint8  \n",
      " 9   embark_town_Southampton  498 non-null    uint8  \n",
      "dtypes: float64(2), int64(5), uint8(3)\n",
      "memory usage: 32.6 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "744cc9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns='survived')\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns='survived')\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns='survived')\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62a70d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id most frequent value for creating baseline\n",
    "y_train.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebcb3ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6164658634538153"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create baseline with 0 value\n",
    "baseline = (y_train == 0).mean()\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4977a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 features\n",
    "logit1 = LogisticRegression(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14895a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['age', 'fare', 'pclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c81cdd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=123)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit1.fit(X_train[features],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3ebd304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.03063266  0.00141012 -0.94966047]]\n",
      "Intercept: \n",
      " [2.52857789]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit1.coef_)\n",
    "print('Intercept: \\n', logit1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "302ab425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logit1.predict(X_train[features])\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f524a66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36988206, 0.63011794],\n",
       "       [0.63810638, 0.36189362],\n",
       "       [0.61748053, 0.38251947],\n",
       "       [0.70385285, 0.29614715],\n",
       "       [0.30445826, 0.69554174]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = logit1.predict_proba(X_train[features])\n",
    "y_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42e4a7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[266  41]\n",
      " [107  84]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05821ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78       307\n",
      "           1       0.67      0.44      0.53       191\n",
      "\n",
      "    accuracy                           0.70       498\n",
      "   macro avg       0.69      0.65      0.66       498\n",
      "weighted avg       0.70      0.70      0.69       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e2b27f",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 2) Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b21359e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['age', 'pclass', 'fare', 'sex_male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "344a529b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8132530120481928\n"
     ]
    }
   ],
   "source": [
    "# 4 features \n",
    "logit2 = LogisticRegression(random_state=123)\n",
    "logit2.fit(X_train[features], y_train)\n",
    "print(logit2.score(X_train[features], y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdacf1e1",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 3) Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3688ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8132530120481928\n"
     ]
    }
   ],
   "source": [
    "# all features\n",
    "logit3 = LogisticRegression(random_state=123)\n",
    "logit3.fit(X_train, y_train)\n",
    "print(logit3.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e7efa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8012048192771084\n"
     ]
    }
   ],
   "source": [
    "# 4 features with class_weight=balanced\n",
    "logit4 = LogisticRegression(random_state=123, class_weight='balanced')\n",
    "logit4.fit(X_train[features], y_train)\n",
    "print(logit4.score(X_train[features], y_train).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56df3cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8072289156626506\n"
     ]
    }
   ],
   "source": [
    "# all features with class_weight=balanced\n",
    "logit5 = LogisticRegression(random_state=123, class_weight='balanced')\n",
    "logit5.fit(X_train, y_train)\n",
    "print(logit5.score(X_train, y_train).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75cd44c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6445783132530121\n"
     ]
    }
   ],
   "source": [
    "# 4 features with c=.001\n",
    "logit6 = LogisticRegression(random_state=123, C=.0001)\n",
    "logit6.fit(X_train[features], y_train)\n",
    "print(logit6.score(X_train[features], y_train).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcb56cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6485943775100401\n"
     ]
    }
   ],
   "source": [
    "# all feature with c=.001\n",
    "logit7 = LogisticRegression(random_state=123, C=.001)\n",
    "logit7.fit(X_train, y_train)\n",
    "print(logit7.score(X_train, y_train).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f37d6fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6847389558232931\n"
     ]
    }
   ],
   "source": [
    "# a4 feature with class_weight='balanced and c=.001\n",
    "logit8 = LogisticRegression(random_state=123, class_weight='balanced',C=.001)\n",
    "logit8.fit(X_train[features], y_train)\n",
    "print(logit8.score(X_train[features], y_train).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e5bf893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6847389558232931\n"
     ]
    }
   ],
   "source": [
    "# all feature with class_weight='balanced and c=.001\n",
    "logit9 = LogisticRegression(random_state=123, class_weight='balanced', C=.001)\n",
    "logit9.fit(X_train, y_train)\n",
    "print(logit9.score(X_train, y_train).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd4857",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 4) Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472eed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit2,logit3, and logit5 has the highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fff2aa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       132\n",
      "           1       0.72      0.67      0.70        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.76      0.76       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#logit2 with 4 features\n",
    "y_pred2 = logit2.predict(X_validate[features])\n",
    "print(classification_report(y_validate, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02082df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.82       132\n",
      "           1       0.74      0.65      0.69        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.77      0.75      0.76       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logit3 with all features\n",
    "y_pred3 = logit3.predict(X_validate)\n",
    "print(classification_report(y_validate, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a519d017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       132\n",
      "           1       0.71      0.71      0.71        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.76      0.76       214\n",
      "weighted avg       0.78      0.78      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logi5 with all features and class_weight='balanced'\n",
    "y_pred5 = logit5.predict(X_validate)\n",
    "print(classification_report(y_validate, y_pred5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2315ea3f",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 5) Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d805d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       110\n",
      "           1       0.77      0.71      0.74        69\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.79      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logit2 with 4 features performed the best\n",
    "y_pred2 = logit2.predict(X_test[features])\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc3657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train: .81\n",
    "# validate: .78\n",
    "# test: .80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce1001a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
