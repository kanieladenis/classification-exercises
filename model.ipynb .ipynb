{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021f5267",
   "metadata": {},
   "source": [
    "# Decision Tree Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3136fc3",
   "metadata": {},
   "source": [
    "#### Using Titanic Data\n",
    "- Remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caaae70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dc24f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire Data\n",
    "df = acquire.get_titanic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "785bb9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.prep_titanic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d12667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Titanic Data\n",
    "df = prepare.clean_titanic(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "train, validate, test = prepare.split_titanic(df)\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66871a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute embark_town for Mode\n",
    "train, validate, test = prepare.impute_titanic_mode(train, validate, test)\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd04af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Age for Mean\n",
    "train, validate, test = prepare.impute_mean_age(train, validate, test)\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2898b7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 498 entries, 583 to 744\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   survived                 498 non-null    int64  \n",
      " 1   pclass                   498 non-null    int64  \n",
      " 2   age                      498 non-null    float64\n",
      " 3   sibsp                    498 non-null    int64  \n",
      " 4   parch                    498 non-null    int64  \n",
      " 5   fare                     498 non-null    float64\n",
      " 6   embark_town              498 non-null    object \n",
      " 7   alone                    498 non-null    int64  \n",
      " 8   sex_male                 498 non-null    uint8  \n",
      " 9   embark_town_Queenstown   498 non-null    uint8  \n",
      " 10  embark_town_Southampton  498 non-null    uint8  \n",
      "dtypes: float64(2), int64(5), object(1), uint8(3)\n",
      "memory usage: 36.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ea807",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 1a) What is your baseline prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e622ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns='survived')\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns='survived')\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns='survived')\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53a53615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find most often used case in survived\n",
    "y_train.value_counts() #most frequent is not_survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb98ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id\n",
       "583     True\n",
       "165    False\n",
       "50      True\n",
       "259    False\n",
       "306    False\n",
       "Name: survived, dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The mode is a great baseline\n",
    "baseline = y_train.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = (y_train == 0)\n",
    "matches_baseline_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "458dbbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Baseline Prediction to 0 or Not_Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5c953",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 1a) What is your baseline accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2b311a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")### ??? Removed column for baseline because it threw off the validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035a165",
   "metadata": {},
   "source": [
    "### Baseline accuracy is 61.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb885e",
   "metadata": {},
   "source": [
    "## <font color = 'red'>2) Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082e8e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501dc36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62adcc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3b9a10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=123)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Decision Tree Object\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa5d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf3814e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Cherbourg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a60850d87270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \"\"\"\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             X, y = self._validate_data(X, y,\n\u001b[0m\u001b[1;32m    157\u001b[0m                                        validate_separately=(check_X_params,\n\u001b[1;32m    158\u001b[0m                                                             check_y_params))\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;31m# :(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Cherbourg'"
     ]
    }
   ],
   "source": [
    "# Fit the Model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f8df4f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-dbf5deeeb29c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'titanic_decision_tree'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[1;32m    767\u001b[0m     \"\"\"\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m     \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m     \u001b[0mown_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0mreturn_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "dot_data = export_graphviz(clf, feature_names= X_train.columns, rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c6b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction on train obeservations\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb541a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide probabiblity on train observations\n",
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c382cb",
   "metadata": {},
   "source": [
    "## <font color = 'red' >3) Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bf7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computer Accuracy Score\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba2241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Confusion Matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff90b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3b9402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Classification Report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942bf140",
   "metadata": {},
   "source": [
    "## <font color = 'red'>4) Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c618c9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find true positive rate, false positive rate, true negative rate, false negative rate\n",
    "# Compute TPR,TNR,FPR,FNR\n",
    "TP = 294\n",
    "TN = 114\n",
    "FP = 77\n",
    "FN = 13\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "accuracy = (TP + TN) / ALL\n",
    "TPR = TP / (TP + FN) \n",
    "TNR = TN / (TN + FP) \n",
    "FNR = FN / (FN + TP)  \n",
    "FPR = FP / (FP + TN) \n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1_score = 2* (precision*recall) / (precision+recall)\n",
    "support_pos = TP + FN\n",
    "support_neg = TN + FP\n",
    "\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'True Positive Rate: {TPR}')\n",
    "print(f'True Negative Rate: {TNR}')\n",
    "print(f'False Positive Rate: {FPR}')\n",
    "print(f'False Negative Rate: {FNR}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "print(f'support_pos: {support_pos}')\n",
    "print(f'support_neg: {support_neg}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ebd73c",
   "metadata": {},
   "source": [
    "## <font color = 'red'>5) Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dd8a62",
   "metadata": {},
   "source": [
    "### <font color = 'red'> Using Max_Depth 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cf3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object increasing max_depth to 4\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=123)\n",
    "# Fit the Model\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f317e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction on train obeservations\n",
    "y_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae7175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find probability of train observations\n",
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33058fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Accuracy\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1520596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Confusion Matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8217bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838be5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b58ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create classification report to find precision, reall, f1-score, support\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20507a0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find true positive rate, false positive rate, true negative rate, false negative rate\n",
    "# Compute TPR,TNR,FPR,FNR\n",
    "TP = 298\n",
    "TN = 116\n",
    "FP = 75\n",
    "FN = 9\n",
    "\n",
    "TPR = TP / (TP + FN) \n",
    "TNR = TN / (TN + FP) \n",
    "FNR = FN / (FN + TP)  \n",
    "FPR = FP / (FP + TN) \n",
    "\n",
    "\n",
    "print(f'True Positive Rate: {TPR}')\n",
    "print(f'True Negative Rate: {TNR}')\n",
    "print(f'False Positive Rate: {FPR}')\n",
    "print(f'False Negative Rate: {FNR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830f5fa8",
   "metadata": {},
   "source": [
    "### <font color = 'red'> Using Max_Depth 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f636048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object increasing max_depth to 5\n",
    "clf = DecisionTreeClassifier(max_depth=5, random_state=123)\n",
    "# Fit the Model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "# make prediction on train obeservations\n",
    "y_pred = clf.predict(X_train)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bf6055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Accuracy\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fabad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424dd34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find true positive rate, false positive rate, true negative rate, false negative rate\n",
    "# Compute TPR,TNR,FPR,FNR\n",
    "TP = 291\n",
    "TN = 131\n",
    "FP = 60\n",
    "FN = 16\n",
    "\n",
    "TPR = TP / (TP + FN) \n",
    "TNR = TN / (TN + FP) \n",
    "FNR = FN / (FN + TP)  \n",
    "FPR = FP / (FP + TN) \n",
    "\n",
    "\n",
    "print(f'True Positive Rate: {TPR}')\n",
    "print(f'True Negative Rate: {TNR}')\n",
    "print(f'False Positive Rate: {FPR}')\n",
    "print(f'False Negative Rate: {FNR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3635aa",
   "metadata": {},
   "source": [
    "### <font color = 'red'> Using Max_Depth 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b394707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object increasing max_depth to 6\n",
    "clf = DecisionTreeClassifier(max_depth=6, random_state=123)\n",
    "# Fit the Model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "# make prediction on train obeservations\n",
    "y_pred = clf.predict(X_train)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061481ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Accuracy\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc10d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc77542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find true positive rate, false positive rate, true negative rate, false negative rate\n",
    "# Compute TPR,TNR,FPR,FNR\n",
    "TP = 282\n",
    "TN = 151\n",
    "FP = 40\n",
    "FN = 25\n",
    "\n",
    "TPR = TP / (TP + FN) \n",
    "TNR = TN / (TN + FP) \n",
    "FNR = FN / (FN + TP)  \n",
    "FPR = FP / (FP + TN) \n",
    "\n",
    "\n",
    "print(f'True Positive Rate: {TPR}')\n",
    "print(f'True Negative Rate: {TNR}')\n",
    "print(f'False Positive Rate: {FPR}')\n",
    "print(f'False Negative Rate: {FNR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9903ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,20):\n",
    "    # Create the Decision Tree Object increasing max_depth to 6\n",
    "    clf = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "    \n",
    "    # Fit the Model\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction on train obeservations\n",
    "    y_pred = clf.predict(X_train)\n",
    "    \n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_pred, output_dict=True)\n",
    "    print(f\"Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66051666",
   "metadata": {},
   "source": [
    "## <font color='red'>6) Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe16be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model using Max Depth 6 because it has the best accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b75cdca",
   "metadata": {},
   "source": [
    "## <font color = 'red'>7) Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9295e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object increasing max_depth to 3\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "# Fit the Model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "# make prediction on train obeservations\n",
    "y_pred = clf.predict(X_validate)\n",
    "\n",
    "print(clf.score(X_validate, y_validate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db06571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b731d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8511f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object increasing max_depth to 4\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=123)\n",
    "# Fit the Model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_validate, y_validate))\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc04d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object increasing max_depth to 5\n",
    "clf = DecisionTreeClassifier(max_depth=5, random_state=123)\n",
    "# Fit the Model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_validate, y_validate))\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af883ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object increasing max_depth to 6\n",
    "clf = DecisionTreeClassifier(max_depth=6, random_state=123)\n",
    "# Fit the Model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_validate, y_validate))\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d544aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(2, 25):\n",
    "    # Make the model\n",
    "    clf = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = clf.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = clf.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca32f1",
   "metadata": {},
   "source": [
    "### Model with Max_Depth 6 has the best F1-Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bfb3d4",
   "metadata": {},
   "source": [
    "# <font color='red'> Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586a5053",
   "metadata": {},
   "source": [
    "##  <font color='red'> 1) Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a219d154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Model's Object\n",
    "rf = RandomForestClassifier(max_depth=10,\n",
    "                           random_state=123,\n",
    "                           min_samples_leaf=1)\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5957a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the Data to the model\n",
    "rf = rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a386683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Feature (column) Importances. sex_male (48%) has the most importance\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "y_pred = rf.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b80aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Probabability of each Prediction\n",
    "y_pred_proba = rf.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1336d368",
   "metadata": {},
   "source": [
    "##  <font color='red'> 2) Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd68dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Model Score for Accuracy\n",
    "rf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f3d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Confusion Matrix\n",
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48feca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70606050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_pred, output_dict=True)\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43fb93a",
   "metadata": {},
   "source": [
    "##  <font color='red'> 3) Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 293\n",
    "FP = 56\n",
    "FN = 14\n",
    "TN = 135\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1367c27d",
   "metadata": {},
   "source": [
    "##  <font color='red'> 4) Run through steps increasing your min_samples_leaf and decreasing your max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8157fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    rf = RandomForestClassifier(max_depth=11-i,\n",
    "                           random_state=123,\n",
    "                           min_samples_leaf=i)\n",
    "    rf = rf.fit(X_train,y_train)\n",
    "    y_pred = rf.predict(X_train)\n",
    "    report = classification_report(y_train, y_pred, output_dict=True)\n",
    "    print(f\"Random Forest with max_depth of {11-i} and min_sample_leaf {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b72f46",
   "metadata": {},
   "source": [
    "##  <font color='red'> 5a) What are the differences in the evaluation metrics? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c012ab",
   "metadata": {},
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24532ee",
   "metadata": {},
   "source": [
    "##  <font color='red'> 5a)Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae93bbda",
   "metadata": {},
   "source": [
    "Random Forest with max_depth of 8 and min_sample_leaf 3 performs best. ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dd2c14",
   "metadata": {},
   "source": [
    "##  <font color='red'> 6) After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070931b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    # Make the model\n",
    "    rf = RandomForestClassifier(max_depth=11-i,\n",
    "                           random_state=123,\n",
    "                           min_samples_leaf=i)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = rf.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = rf.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": 11-i,\n",
    "        \"min_sample\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b70ebe",
   "metadata": {},
   "source": [
    "### model with max_depth = 2, min_sample = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d49069",
   "metadata": {},
   "source": [
    "# <font color = 'red'> K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db0bddb",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 1) Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7e83b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model object\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit data to model object\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3618d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prediction array based on train data set using model\n",
    "y_pred = knn.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5867763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See class of data. 0=Did Not Surviv, 1 = Survived\n",
    "knn.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Probablity of Prediction (Did Not Survive) being correction\n",
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da1e722",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 2) Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy Score for KNN. 83% accurate\n",
    "knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bbe17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Confusion Matrix\n",
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f7a3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815a565d",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 3) Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e3d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 273\n",
    "TN = 139\n",
    "FP = 52\n",
    "FN = 34\n",
    "\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de83828",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 4) Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb32f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model object based on k = 10\n",
    "knn = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "# fit data to model object\n",
    "knn.fit(X_train, y_train)\n",
    "# Create Prediction Array\n",
    "y_pred = knn.predict(X_train)\n",
    "\n",
    "print(knn.score(X_train, y_train))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3464faf9",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 5) Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59772000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model object based on k = 20\n",
    "knn = KNeighborsClassifier(n_neighbors=20, weights='uniform')\n",
    "# fit data to model object\n",
    "knn.fit(X_train, y_train)\n",
    "# Create Prediction Array\n",
    "y_pred = knn.predict(X_train)\n",
    "\n",
    "print(knn.score(X_train, y_train))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f14a8",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 6) What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9028a",
   "metadata": {},
   "source": [
    "### Model with K=10 provides 81% Accuracy vs Model with K=20 provides 82% Accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a243cc0",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 7) Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3707f5b",
   "metadata": {},
   "source": [
    "### Model with K=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62273c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model object based on k = 10\n",
    "knn = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "# fit data to model object\n",
    "knn.fit(X_train, y_train)\n",
    "# Create Prediction Array\n",
    "y_pred = knn.predict(X_train)\n",
    "\n",
    "print(knn.score(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bbc1a6",
   "metadata": {},
   "source": [
    "### Model with K=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc71eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model object based on k = 20\n",
    "knn = KNeighborsClassifier(n_neighbors=20, weights='uniform')\n",
    "# fit data to model object\n",
    "knn.fit(X_train, y_train)\n",
    "# Create Prediction Array\n",
    "y_pred = knn.predict(X_train)\n",
    "\n",
    "print(knn.score(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48c6ac9",
   "metadata": {},
   "source": [
    "### Model with K=10 has better accuracy because K=20 includes too much noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d4382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(1,21):\n",
    "    # Make the model\n",
    "    knn = KNeighborsClassifier(n_neighbors=i, weights='uniform')\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    knn = knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = knn.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = knn.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"K_Neighbor\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c17b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.difference.abs().idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7480f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1, 21)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,5,10,15,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b1666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id columns\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee340c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce features\n",
    "x_cols = ['pclass','alone', 'sex_male']\n",
    "y_col = 'survived'\n",
    "\n",
    "X_train, y_train = train[x_cols], train[y_col]\n",
    "X_validate, y_validate = validate[x_cols], validate[y_col]\n",
    "X_test, y_test = test[x_cols], test[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca134cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(1,21):\n",
    "    # Make the model\n",
    "    knn = KNeighborsClassifier(n_neighbors=i, weights='uniform')\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    knn = knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = knn.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = knn.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"K_Neighbor\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.difference.abs().idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c6de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "# loop through different values of k\n",
    "for k in range(1, 21):\n",
    "            \n",
    "    # define the thing\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # fit the thing (remmeber only fit on training data)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # use the thing (calculate accuracy)\n",
    "    train_accuracy = knn.score(X_train, y_train)\n",
    "    validate_accuracy = knn.score(X_validate, y_validate)\n",
    "    \n",
    "    output = {\n",
    "        \"k\": k,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"validate_accuracy\": validate_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "\n",
    "# make a dataframe\n",
    "results = pd.DataFrame(metrics)\n",
    "\n",
    "# plot the data\n",
    "results.set_index('k').plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e1c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce features\n",
    "x_cols = ['pclass','alone', 'sex_male']\n",
    "y_col = 'survived'\n",
    "\n",
    "X_train, y_train = train[x_cols], train[y_col]\n",
    "X_validate, y_validate = validate[x_cols], validate[y_col]\n",
    "X_test, y_test = test[x_cols], test[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2533882",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "# loop through different values of k\n",
    "for k in range(1, 21):\n",
    "            \n",
    "    # define the thing\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # fit the thing (remmeber only fit on training data)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # use the thing (calculate accuracy)\n",
    "    train_accuracy = knn.score(X_train, y_train)\n",
    "    validate_accuracy = knn.score(X_validate, y_validate)\n",
    "    \n",
    "    output = {\n",
    "        \"k\": k,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"validate_accuracy\": validate_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "\n",
    "# make a dataframe\n",
    "results = pd.DataFrame(metrics)\n",
    "\n",
    "# plot the data\n",
    "results.set_index('k').plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e558966d",
   "metadata": {},
   "source": [
    "# <font color='red'> Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec305185",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 1) Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fda602d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4e2b27f",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 2) Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdacf1e1",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 3) Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd4857",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 4) Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2315ea3f",
   "metadata": {},
   "source": [
    "## <font color = 'red'> 5) Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d805d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc3657f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce1001a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
